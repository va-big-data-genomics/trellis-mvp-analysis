{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neo4J v1.0 - Trellis : Job based Analysis\n",
    "================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the environment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install py2neo for querying Neo4J "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install -U py2neo\n",
    "\n",
    "# add python path of py2neo in system\n",
    "\n",
    "#!pip3 install -U neotime\n",
    "#!pip3 install -U neobolt\n",
    "#!pip3 install -U pandas-gbq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py2neo import Graph\n",
    "from google.cloud import storage\n",
    "import yaml\n",
    "\n",
    "import pandas as pd\n",
    "import pandas_gbq\n",
    "\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#plt.style.use('fivethirtyeight')\n",
    "#plt.style.use('ggplot')\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Neo4J DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "bucket_info=''\n",
    "credential_info=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Option 1 : Read DB and Account Information in Google Storage (YAML)\n",
    "\n",
    "# create storage client\n",
    "storage_client = storage.Client()\n",
    "# get bucket with name\n",
    "bucket = storage_client.get_bucket(bucket_info)\n",
    "# get bucket data as blob\n",
    "blob = bucket.get_blob(credential_info)\n",
    "# convert to string\n",
    "yaml_data = blob.download_as_string()\n",
    "\n",
    "account = yaml.load(yaml_data, Loader=yaml.FullLoader)\n",
    "\n",
    "## Main Account\n",
    "graph = Graph(account['NEO4J_SCHEME']+'://'+account['NEO4J_HOST']+\":\"+str(account['NEO4J_PORT']), auth=(account['NEO4J_USER'],account['NEO4J_PASSPHRASE']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "## FQ2U Job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FQ2U table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of samples with FQ2U jobs : 288\n",
      "The number of FQ2U jobs : 1156\n"
     ]
    }
   ],
   "source": [
    "## Query\n",
    "query = \"Match (fu:Job:FastqToUbam)-[:STATUS]->(s:Dstat) RETURN fu.sample AS sample, fu.readGroup AS fq2urg_gatkid, fu.duplicate AS dup, fu.machineType AS vm_type, fu.durationMinutes as job_runtime, s.status as dstat_status, s.statusMessage as dstat_msg, s.logging as dstat_log\"\n",
    "job_fq2u = graph.run(query).to_data_frame()\n",
    "job_fq2u.set_index('sample')\n",
    "\n",
    "## Variable\n",
    "num_fq2u_sample=len(job_fq2u['sample'].unique())\n",
    "num_fq2u_job=len(job_fq2u)\n",
    "\n",
    "## Print (Info)\n",
    "print(\"The number of samples with FQ2U jobs : \" + str(num_fq2u_sample))\n",
    "print(\"The number of FQ2U jobs : \" + str(num_fq2u_job))\n",
    "\n",
    "## Bigquery Table Format\n",
    "job_fq2u['job_group']='GATK'\n",
    "job_fq2u['vm_exp_cnt']=1\n",
    "job_fq2u['job']='FQ2U'\n",
    "job_fq2u['vm_cnt']=1\n",
    "job_fq2u['vm_disk']=None\n",
    "job_fq2u['vm_avg_runtime']=job_fq2u['job_runtime']\n",
    "columnlist=['sample','job_group','job','fq2urg_gatkid','dup','vm_exp_cnt','vm_cnt','vm_avg_runtime','job_runtime','vm_type','vm_disk','dstat_status','dstat_msg','dstat_log']\n",
    "job_fq2u=job_fq2u[columnlist]\n",
    "\n",
    "#display(job_fq2u.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FQ2U Duplication Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number(percentage) of samples with duplicated FQ2U jobs : 0 (0.000000%)\n",
      "The number(percentage) of FQ2U duplicated jobs : 0 (0.000000%)\n"
     ]
    }
   ],
   "source": [
    "## Query\n",
    "fq2u_dup=job_fq2u.loc[job_fq2u['dup']==True,:]\n",
    "\n",
    "## Variable\n",
    "num_dup_fq2u_sample=len(fq2u_dup['sample'].unique())\n",
    "num_dup_fq2u_job=len(fq2u_dup)\n",
    "\n",
    "print(\"The number(percentage) of samples with duplicated FQ2U jobs : \" + str(len(fq2u_dup['sample'].unique()))+\" (\"+'{:2f}'.format((num_dup_fq2u_sample/num_fq2u_sample)*100)+\"%)\")\n",
    "print(\"The number(percentage) of FQ2U duplicated jobs : \" + str(num_dup_fq2u_job)+\" (\"+'{:2f}'.format((num_dup_fq2u_job/num_fq2u_job)*100)+\"%)\")\n",
    "\n",
    "#display(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "## GATK Job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GATK table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of samples with GATK jobs : 287\n",
      "The number of GATK jobs : 287\n"
     ]
    }
   ],
   "source": [
    "## Query\n",
    "query = \"MATCH (j:Job:CromwellWorkflow)-[:STATUS]->(s:Dstat) RETURN j.sample AS sample, j.cromwellWorkflowId AS fq2urg_gatkid, \\\n",
    "j.duplicate AS dup, j.durationMinutes as job_runtime, j.machineType as vm_type, s.status as dstat_status, s.statusMessage as dstat_msg, s.logging as dstat_log\"\n",
    "job_gatk = graph.run(query).to_data_frame()\n",
    "job_gatk.set_index('sample')\n",
    "\n",
    "## Variable\n",
    "num_gatk_sample=len(job_gatk['sample'].unique())\n",
    "num_gatk_job=len(job_gatk)\n",
    "\n",
    "## Print (Info)\n",
    "print(\"The number of samples with GATK jobs : \" + str(num_gatk_sample))\n",
    "print(\"The number of GATK jobs : \" + str(num_gatk_job))\n",
    "\n",
    "## Bigquery Table Format\n",
    "job_gatk['job_group']='GATK'\n",
    "job_gatk['vm_exp_cnt']=1\n",
    "job_gatk['job']='cromwell'\n",
    "job_gatk['vm_cnt']=1\n",
    "job_gatk['vm_avg_runtime']=job_gatk['job_runtime']\n",
    "job_gatk['vm_disk']=None\n",
    "columnlist=['sample','job_group','job','fq2urg_gatkid','dup','vm_exp_cnt','vm_cnt','vm_avg_runtime','job_runtime','vm_type','vm_disk','dstat_status','dstat_msg','dstat_log']\n",
    "job_gatk=job_gatk[columnlist]\n",
    "\n",
    "#display(job_gatk.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GATK Duplication Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number(percentage) of samples with duplicated GATK jobs : 0 (0.000000%)\n",
      "The number(percentage) of GATK duplicated jobs : 0 (0.000000%)\n"
     ]
    }
   ],
   "source": [
    "## Query\n",
    "gatk_dup=job_gatk.loc[job_gatk['dup']==True,:]\n",
    "\n",
    "## Variable\n",
    "num_dup_gatk_sample=len(gatk_dup['sample'].unique())\n",
    "num_dup_gatk_job=len(gatk_dup)\n",
    "\n",
    "print(\"The number(percentage) of samples with duplicated GATK jobs : \" + str(len(gatk_dup['sample'].unique()))+\" (\"+'{:2f}'.format((num_dup_gatk_sample/num_gatk_sample)*100)+\"%)\")\n",
    "print(\"The number(percentage) of GATK duplicated jobs : \" + str(num_dup_gatk_job)+\" (\"+'{:2f}'.format((num_dup_gatk_job/num_gatk_job)*100)+\"%)\")\n",
    "\n",
    "#display(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GATK vm_exp_cnt and add_vm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## expected vm data frame\n",
    "#vm_exp_cnt_df=pd.read_excel(\"./GATKstep_expected_vm.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merged_vm_cnt_df=pd.merge(vm_exp_cnt_df,job_gatk,left_on=['job'],right_on=['job'],how='right')\n",
    "#merged_attemps_df['added_vm']=job_gatk['vm_cnt']-merged_attemps_df['vm_exp_cnt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "## GATK substeps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vm_cnt table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of samples with GATK steps : 287\n",
      "The number of GATK subjobs : 4632\n"
     ]
    }
   ],
   "source": [
    "## Query\n",
    "#query = \"MATCH (g:Job:CromwellWorkflow)-[:LED_TO*]->(s:CromwellStep)-[:HAS_ATTEMPT]-()-[*0..100]->(j:Job) \\\n",
    "#WHERE g.cromwellWorkflowId=s.cromwellWorkflowId RETURN g.sample as sample, s.cromwellWorkflowId as fq2urg_gatkid, \\\n",
    "#s.wdlCallAlias as job, count(distinct j) as vm_cnt, (max(j.stopTimeEpoch)-min(j.startTimeEpoch))/60 as job_runtime, avg(j.durationMinutes) as vm_avg_runtime, j.machineType as vm_type\"\n",
    "query = \"MATCH (g:Job:CromwellWorkflow), (s:CromwellStep)-[:HAS_ATTEMPT]-()-[*0..100]->(j:Job) \\\n",
    "WHERE g.cromwellWorkflowId=s.cromwellWorkflowId RETURN g.sample as sample, s.cromwellWorkflowId as fq2urg_gatkid, \\\n",
    "s.wdlCallAlias as job, count(distinct j) as vm_cnt, (max(j.stopTimeEpoch)-min(j.startTimeEpoch))/60 as job_runtime, avg(j.durationMinutes) as vm_avg_runtime, j.machineType as vm_type\"\n",
    "#query = \"MATCH (j:Job:CromwellWorkflow)-[:STATUS]->(s:Dstat) RETURN j.sample AS sample, j.duplicate AS dup, j.durationMinutes as job_runtime, s.status as dstat_status, s.statusMessage as dstat_msg, s.logging as dstat_log\"\n",
    "job_gatk_step = graph.run(query).to_data_frame()\n",
    "job_gatk_step.set_index('sample')\n",
    "\n",
    "## Variable\n",
    "num_gatk_sample=len(job_gatk_step['sample'].unique())\n",
    "num_gatk_subjobs=len(job_gatk_step)\n",
    "\n",
    "## Print (Info)\n",
    "print(\"The number of samples with GATK steps : \" + str(num_gatk_sample))\n",
    "print(\"The number of GATK subjobs : \" + str(num_gatk_subjobs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GATK Duplication Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bigquery Table Format\n",
    "job_gatk_step['job_group']='GATK'\n",
    "job_gatk_step['vm_disk']=None\n",
    "\n",
    "job_gatk_info=job_gatk[['sample','fq2urg_gatkid','dup','dstat_status','dstat_msg','dstat_log']]\n",
    "job_gatk_stepm=pd.merge(job_gatk_info, job_gatk_step, left_on=['sample','fq2urg_gatkid'], right_on=['sample','fq2urg_gatkid'], how='right')\n",
    "\n",
    "#display(job_gatk_stepm.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GATK vm_exp_cnt and add_vm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## expected vm data frame\n",
    "vm_exp_cnt_file = 'gs://'+account['TRELLIS_BUCKET']+'/analysis-notebooks/GATKstep_expected_vm.xlsx'\n",
    "vm_exp_cnt_df=pd.read_excel(vm_exp_cnt_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_gatk_stepm=pd.merge(vm_exp_cnt_df,job_gatk_stepm,left_on=['job'],right_on=['job'],how='right')\n",
    "columnlist=['sample','job_group','job','fq2urg_gatkid','dup','vm_exp_cnt','vm_cnt','vm_avg_runtime','job_runtime','vm_type','vm_disk','dstat_status','dstat_msg','dstat_log']\n",
    "job_gatk_stepm=job_gatk_stepm[columnlist]\n",
    "#merged_attemps_df['added_vm']=job_gatk['vm_cnt']-merged_attemps_df['vm_exp_cnt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "## QC Job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fastqc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows : 288\n",
      "The number of duplicated jobs : 0\n",
      "The number of rows dropped duplications : 287\n"
     ]
    }
   ],
   "source": [
    "query=\"MATCH (j:Job:BamFastqc)-[:STATUS]->(d:Dstat) RETURN j.sample as sample, j.name as job, j.duplicate as dup, j.machineType as vm_type, j.durationMinutes as job_runtime, j.diskSize as vm_disk, d.status as dstat_status, d.statusMessage as dstat_msg, d.logging as dstat_log\"\n",
    "job_fastqc = graph.run(query).to_data_frame()\n",
    "\n",
    "job_fastqc['job_group']='QC'\n",
    "job_fastqc['fq2urg_gatkid']=None\n",
    "job_fastqc['vm_exp_cnt']=1\n",
    "job_fastqc['vm_cnt']=1\n",
    "job_fastqc['vm_avg_runtime']=job_fastqc['job_runtime']\n",
    "\n",
    "job_fastqc=job_fastqc[columnlist]\n",
    "job_fastqc.set_index('sample')\n",
    "\n",
    "## duplication check\n",
    "\n",
    "print('The number of rows : ' + str(len(job_fastqc)))\n",
    "print('The number of duplicated jobs : ' + str(len(job_fastqc.loc[job_fastqc['dup']==True,:])))\n",
    "\n",
    "job_fastqc.drop_duplicates(columnlist,keep='first',inplace=True)\n",
    "\n",
    "print('The number of rows dropped duplications : ' + str(len(job_fastqc)))\n",
    "\n",
    "## column order\n",
    "\n",
    "columnlist=['sample','job_group','job','fq2urg_gatkid','dup','vm_exp_cnt','vm_cnt','vm_avg_runtime','job_runtime','vm_type','vm_disk','dstat_status','dstat_msg','dstat_log']\n",
    "job_fastqc=job_fastqc[columnlist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text2table for Fastqc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows : 286\n",
      "The number of duplicated jobs : 0\n",
      "The number of rows dropped duplications : 285\n"
     ]
    }
   ],
   "source": [
    "query=\"MATCH (j:Job:BamFastqc)-[:GENERATED]->()-[:WAS_USED_BY]->(t:Job:TextToTable)-[:STATUS]->(d:Dstat) RETURN j.sample as sample, j.name as fq2urg_gatkid, t.name as job, t.duplicate as dup, t.machineType as vm_type, t.durationMinutes as job_runtime, t.diskSize as vm_disk, d.status as dstat_status, d.statusMessage as dstat_msg, d.logging as dstat_log\"\n",
    "job_fastqc_t2t=graph.run(query).to_data_frame()\n",
    "\n",
    "job_fastqc_t2t['job_group']='QC'\n",
    "job_fastqc_t2t['vm_exp_cnt']=1\n",
    "job_fastqc_t2t['vm_cnt']=1\n",
    "job_fastqc_t2t['vm_avg_runtime']=job_fastqc_t2t['job_runtime']\n",
    "\n",
    "job_fastqc_t2t=job_fastqc_t2t[columnlist]\n",
    "job_fastqc_t2t.set_index('sample')\n",
    "\n",
    "## duplication check\n",
    "\n",
    "print('The number of rows : ' + str(len(job_fastqc_t2t)))\n",
    "print('The number of duplicated jobs : ' + str(len(job_fastqc_t2t.loc[job_fastqc_t2t['dup']==True,:])))\n",
    "\n",
    "## drop duplication\n",
    "\n",
    "job_fastqc_t2t.drop_duplicates(columnlist,keep='first',inplace=True)\n",
    "print('The number of rows dropped duplications : ' + str(len(job_fastqc_t2t)))\n",
    "\n",
    "## column order\n",
    "\n",
    "columnlist=['sample','job_group','job','fq2urg_gatkid','dup','vm_exp_cnt','vm_cnt','vm_avg_runtime','job_runtime','vm_type','vm_disk','dstat_status','dstat_msg','dstat_log']\n",
    "job_fastqc_t2t=job_fastqc_t2t[columnlist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SHIP5119489', 'SHIP5141877'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#job_fastqc_t2t.loc[job_fastqc_t2t['sample']=='SHIP5119485','dstat_log'][196]\n",
    "#job_fastqc_t2t['sample'].value_counts()\n",
    "\n",
    "## Missing \n",
    "set(job_fastqc['sample'])-set(job_fastqc_t2t['sample'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flagstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows : 288\n",
      "The number of duplicated jobs : 1\n",
      "The number of rows dropped duplications : 288\n"
     ]
    }
   ],
   "source": [
    "query=\"MATCH (s:Sample), (j:Job:Flagstat)-[:STATUS]->(d:Dstat) WHERE s.sample=j.sample RETURN s.sample as sample, j.name as job, j.duplicate as dup, j.machineType as vm_type, j.durationMinutes as job_runtime, j.diskSize as vm_disk, d.status as dstat_status, d.statusMessage as dstat_msg, d.logging as dstat_log\"\n",
    "job_flagstat = graph.run(query).to_data_frame()\n",
    "\n",
    "job_flagstat['job_group']='QC'\n",
    "job_flagstat['fq2urg_gatkid']=None\n",
    "job_flagstat['vm_exp_cnt']=1\n",
    "job_flagstat['vm_cnt']=1\n",
    "job_flagstat['vm_avg_runtime']=job_flagstat['job_runtime']\n",
    "\n",
    "job_flagstat=job_flagstat[columnlist]\n",
    "job_flagstat.set_index('sample')\n",
    "\n",
    "print('The number of rows : ' + str(len(job_flagstat)))\n",
    "print('The number of duplicated jobs : ' + str(len(job_flagstat.loc[job_flagstat['dup']==True,:])))\n",
    "\n",
    "## drop duplication\n",
    "\n",
    "job_flagstat.drop_duplicates(columnlist,keep='first',inplace=True)\n",
    "print('The number of rows dropped duplications : ' + str(len(job_flagstat)))\n",
    "\n",
    "## column order\n",
    "\n",
    "columnlist=['sample','job_group','job','fq2urg_gatkid','dup','vm_exp_cnt','vm_cnt','vm_avg_runtime','job_runtime','vm_type','vm_disk','dstat_status','dstat_msg','dstat_log']\n",
    "job_flagstat=job_flagstat[columnlist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#job_flagstat.loc[job_flagstat['sample']=='SHIP5119453',:]\n",
    "#job_flagstat['sample'].value_counts()\n",
    "\n",
    "## Missing \n",
    "#set(job_fastqc['sample'])-set(job_fastqc_t2t['sample'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### text2table for Flagstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows : 287\n",
      "The number of duplicated jobs : 0\n",
      "The number of rows dropped duplications : 287\n"
     ]
    }
   ],
   "source": [
    "query=\"MATCH (s:Sample), (j:Job:Flagstat)-[:GENERATED]->()-[:WAS_USED_BY]->(t:Job:TextToTable)-[:STATUS]->(d:Dstat) WHERE s.sample=j.sample RETURN s.sample as sample, j.name as fq2urg_gatkid, t.name as job, t.duplicate as dup, t.machineType as vm_type, t.durationMinutes as job_runtime, t.diskSize as vm_disk, d.status as dstat_status, d.statusMessage as dstat_msg, d.logging as dstat_log\"\n",
    "job_flagstat_t2t=graph.run(query).to_data_frame()\n",
    "\n",
    "job_flagstat_t2t['job_group']='QC'\n",
    "job_flagstat_t2t['vm_exp_cnt']=1\n",
    "job_flagstat_t2t['vm_cnt']=1\n",
    "job_flagstat_t2t['vm_avg_runtime']=job_flagstat_t2t['job_runtime']\n",
    "\n",
    "job_flagstat_t2t=job_flagstat_t2t[columnlist]\n",
    "job_flagstat_t2t.set_index('sample')\n",
    "\n",
    "print('The number of rows : ' + str(len(job_flagstat_t2t)))\n",
    "print('The number of duplicated jobs : ' + str(len(job_flagstat_t2t.loc[job_flagstat_t2t['dup']==True,:])))\n",
    "\n",
    "## drop duplication\n",
    "\n",
    "job_flagstat_t2t.drop_duplicates(columnlist,keep='first',inplace=True)\n",
    "print('The number of rows dropped duplications : ' + str(len(job_flagstat_t2t)))\n",
    "\n",
    "columnlist=['sample','job_group','job','fq2urg_gatkid','dup','vm_exp_cnt','vm_cnt','vm_avg_runtime','job_runtime','vm_type','vm_disk','dstat_status','dstat_msg','dstat_log']\n",
    "job_flagstat_t2t=job_flagstat_t2t[columnlist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#job_flagstat_t2t.loc[job_flagstat_t2t['sample']=='SHIP5119453',:]\n",
    "#job_flagstat_t2t['sample'].value_counts()\n",
    "\n",
    "## Missing \n",
    "set(job_flagstat['sample'])-set(job_flagstat_t2t['sample'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vcfstats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows : 287\n",
      "The number of duplicated jobs : 0\n",
      "The number of rows dropped duplications : 287\n"
     ]
    }
   ],
   "source": [
    "query=\"MATCH (s:Sample), (j:Job:Vcfstats)-[:STATUS]->(d:Dstat) WHERE s.sample=j.sample RETURN s.sample as sample, j.name as job, j.duplicate as dup, j.machineType as vm_type, j.durationMinutes as job_runtime, j.diskSize as vm_disk, d.status as dstat_status, d.statusMessage as dstat_msg, d.logging as dstat_log\"\n",
    "job_vcfstats = graph.run(query).to_data_frame()\n",
    "\n",
    "job_vcfstats['job_group']='QC'\n",
    "job_vcfstats['fq2urg_gatkid']=None\n",
    "job_vcfstats['vm_exp_cnt']=1\n",
    "job_vcfstats['vm_cnt']=1\n",
    "job_vcfstats['vm_avg_runtime']=job_vcfstats['job_runtime']\n",
    "\n",
    "job_vcfstats=job_vcfstats[columnlist]\n",
    "job_vcfstats.set_index('sample')\n",
    "\n",
    "print('The number of rows : ' + str(len(job_vcfstats)))\n",
    "print('The number of duplicated jobs : ' + str(len(job_vcfstats.loc[job_vcfstats['dup']==True,:])))\n",
    "\n",
    "## drop duplication\n",
    "\n",
    "job_vcfstats.drop_duplicates(columnlist,keep='first',inplace=True)\n",
    "print('The number of rows dropped duplications : ' + str(len(job_vcfstats)))\n",
    "\n",
    "columnlist=['sample','job_group','job','fq2urg_gatkid','dup','vm_exp_cnt','vm_cnt','vm_avg_runtime','job_runtime','vm_type','vm_disk','dstat_status','dstat_msg','dstat_log']\n",
    "job_vcfstats=job_vcfstats[columnlist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### text2table for Vcfstats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows : 290\n",
      "The number of duplicated jobs : 0\n",
      "The number of rows dropped duplications : 287\n"
     ]
    }
   ],
   "source": [
    "query=\"MATCH (s:Sample), (j:Job:Vcfstats)-[:GENERATED]->()-[:WAS_USED_BY]->(t:Job:TextToTable)-[:STATUS]->(d:Dstat) WHERE s.sample=j.sample RETURN s.sample as sample, j.name as fq2urg_gatkid, t.name as job, t.duplicate as dup, t.machineType as vm_type, t.durationMinutes as job_runtime, t.diskSize as vm_disk, d.status as dstat_status, d.statusMessage as dstat_msg, d.logging as dstat_log\"\n",
    "job_vcfstats_t2t=graph.run(query).to_data_frame()\n",
    "\n",
    "job_vcfstats_t2t['job_group']='QC'\n",
    "job_vcfstats_t2t['vm_exp_cnt']=1\n",
    "job_vcfstats_t2t['vm_cnt']=1\n",
    "job_vcfstats_t2t['vm_avg_runtime']=job_vcfstats_t2t['job_runtime']\n",
    "\n",
    "job_vcfstats_t2t=job_vcfstats_t2t[columnlist]\n",
    "job_vcfstats_t2t.set_index('sample')\n",
    "\n",
    "print('The number of rows : ' + str(len(job_vcfstats_t2t)))\n",
    "print('The number of duplicated jobs : ' + str(len(job_vcfstats_t2t.loc[job_vcfstats_t2t['dup']==True,:])))\n",
    "\n",
    "## drop duplication\n",
    "\n",
    "job_vcfstats_t2t.drop_duplicates(columnlist,keep='first',inplace=True)\n",
    "print('The number of rows dropped duplications : ' + str(len(job_vcfstats_t2t)))\n",
    "\n",
    "columnlist=['sample','job_group','job','fq2urg_gatkid','dup','vm_exp_cnt','vm_cnt','vm_avg_runtime','job_runtime','vm_type','vm_disk','dstat_status','dstat_msg','dstat_log']\n",
    "job_vcfstats_t2t=job_vcfstats_t2t[columnlist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#job_flagstat_t2t.loc[job_flagstat_t2t['sample']=='SHIP5119453',:]\n",
    "#job_vcfstats_t2t['sample'].value_counts()\n",
    "\n",
    "## Missing \n",
    "set(job_vcfstats['sample'])-set(job_vcfstats_t2t['sample'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "## Merge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>job_group</th>\n",
       "      <th>job</th>\n",
       "      <th>fq2urg_gatkid</th>\n",
       "      <th>dup</th>\n",
       "      <th>vm_exp_cnt</th>\n",
       "      <th>vm_cnt</th>\n",
       "      <th>vm_avg_runtime</th>\n",
       "      <th>job_runtime</th>\n",
       "      <th>vm_type</th>\n",
       "      <th>vm_disk</th>\n",
       "      <th>dstat_status</th>\n",
       "      <th>dstat_msg</th>\n",
       "      <th>dstat_log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>SHIP4946367</td>\n",
       "      <td>GATK</td>\n",
       "      <td>FQ2U</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>55.00</td>\n",
       "      <td>55.00</td>\n",
       "      <td>custom-2-7680</td>\n",
       "      <td>None</td>\n",
       "      <td>SUCCESS</td>\n",
       "      <td>Success</td>\n",
       "      <td>gs://gbsc-gcp-project-mvp-test-from-personalis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>SHIP4946367</td>\n",
       "      <td>GATK</td>\n",
       "      <td>FQ2U</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>56.00</td>\n",
       "      <td>56.00</td>\n",
       "      <td>custom-2-7680</td>\n",
       "      <td>None</td>\n",
       "      <td>SUCCESS</td>\n",
       "      <td>Success</td>\n",
       "      <td>gs://gbsc-gcp-project-mvp-test-from-personalis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>SHIP4946367</td>\n",
       "      <td>GATK</td>\n",
       "      <td>FQ2U</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>55.00</td>\n",
       "      <td>55.00</td>\n",
       "      <td>custom-2-7680</td>\n",
       "      <td>None</td>\n",
       "      <td>SUCCESS</td>\n",
       "      <td>Success</td>\n",
       "      <td>gs://gbsc-gcp-project-mvp-test-from-personalis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>SHIP4946367</td>\n",
       "      <td>GATK</td>\n",
       "      <td>FQ2U</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>55.00</td>\n",
       "      <td>55.00</td>\n",
       "      <td>custom-2-7680</td>\n",
       "      <td>None</td>\n",
       "      <td>SUCCESS</td>\n",
       "      <td>Success</td>\n",
       "      <td>gs://gbsc-gcp-project-mvp-test-from-personalis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935</th>\n",
       "      <td>SHIP4946367</td>\n",
       "      <td>GATK</td>\n",
       "      <td>applybqsr</td>\n",
       "      <td>450dc917-48cb-42fe-875e-ca1ca937eabf</td>\n",
       "      <td>None</td>\n",
       "      <td>19.00</td>\n",
       "      <td>20</td>\n",
       "      <td>27.69</td>\n",
       "      <td>51.44</td>\n",
       "      <td>custom-1-3584</td>\n",
       "      <td>None</td>\n",
       "      <td>SUCCESS</td>\n",
       "      <td>Success</td>\n",
       "      <td>gs://gbsc-gcp-project-mvp-test-from-personalis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>SHIP5141934</td>\n",
       "      <td>QC</td>\n",
       "      <td>flagstat</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>31.00</td>\n",
       "      <td>31.00</td>\n",
       "      <td>custom-1-3840</td>\n",
       "      <td>None</td>\n",
       "      <td>SUCCESS</td>\n",
       "      <td>Success</td>\n",
       "      <td>gs://gbsc-gcp-project-mvp-test-from-personalis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>SHIP5141934</td>\n",
       "      <td>QC</td>\n",
       "      <td>text-to-table</td>\n",
       "      <td>bam-fastqc</td>\n",
       "      <td>None</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>custom-1-3840</td>\n",
       "      <td>None</td>\n",
       "      <td>SUCCESS</td>\n",
       "      <td>Success</td>\n",
       "      <td>gs://gbsc-gcp-project-mvp-test-from-personalis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>SHIP5141934</td>\n",
       "      <td>QC</td>\n",
       "      <td>text-to-table</td>\n",
       "      <td>flagstat</td>\n",
       "      <td>None</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>custom-1-3840</td>\n",
       "      <td>None</td>\n",
       "      <td>SUCCESS</td>\n",
       "      <td>Success</td>\n",
       "      <td>gs://gbsc-gcp-project-mvp-test-from-personalis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>SHIP5141934</td>\n",
       "      <td>QC</td>\n",
       "      <td>text-to-table</td>\n",
       "      <td>vcfstats</td>\n",
       "      <td>None</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>custom-1-3840</td>\n",
       "      <td>None</td>\n",
       "      <td>SUCCESS</td>\n",
       "      <td>Success</td>\n",
       "      <td>gs://gbsc-gcp-project-mvp-test-from-personalis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>SHIP5141934</td>\n",
       "      <td>QC</td>\n",
       "      <td>vcfstats</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>23.00</td>\n",
       "      <td>23.00</td>\n",
       "      <td>custom-1-3840</td>\n",
       "      <td>None</td>\n",
       "      <td>SUCCESS</td>\n",
       "      <td>Success</td>\n",
       "      <td>gs://gbsc-gcp-project-mvp-test-from-personalis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7796 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           sample job_group            job  \\\n",
       "309   SHIP4946367      GATK           FQ2U   \n",
       "246   SHIP4946367      GATK           FQ2U   \n",
       "231   SHIP4946367      GATK           FQ2U   \n",
       "218   SHIP4946367      GATK           FQ2U   \n",
       "2935  SHIP4946367      GATK      applybqsr   \n",
       "...           ...       ...            ...   \n",
       "266   SHIP5141934        QC       flagstat   \n",
       "264   SHIP5141934        QC  text-to-table   \n",
       "265   SHIP5141934        QC  text-to-table   \n",
       "258   SHIP5141934        QC  text-to-table   \n",
       "256   SHIP5141934        QC       vcfstats   \n",
       "\n",
       "                             fq2urg_gatkid   dup  vm_exp_cnt  vm_cnt  \\\n",
       "309                                      0  None        1.00       1   \n",
       "246                                      1  None        1.00       1   \n",
       "231                                      2  None        1.00       1   \n",
       "218                                      3  None        1.00       1   \n",
       "2935  450dc917-48cb-42fe-875e-ca1ca937eabf  None       19.00      20   \n",
       "...                                    ...   ...         ...     ...   \n",
       "266                                   None  None        1.00       1   \n",
       "264                             bam-fastqc  None        1.00       1   \n",
       "265                               flagstat  None        1.00       1   \n",
       "258                               vcfstats  None        1.00       1   \n",
       "256                                   None  None        1.00       1   \n",
       "\n",
       "      vm_avg_runtime  job_runtime        vm_type vm_disk dstat_status  \\\n",
       "309            55.00        55.00  custom-2-7680    None      SUCCESS   \n",
       "246            56.00        56.00  custom-2-7680    None      SUCCESS   \n",
       "231            55.00        55.00  custom-2-7680    None      SUCCESS   \n",
       "218            55.00        55.00  custom-2-7680    None      SUCCESS   \n",
       "2935           27.69        51.44  custom-1-3584    None      SUCCESS   \n",
       "...              ...          ...            ...     ...          ...   \n",
       "266            31.00        31.00  custom-1-3840    None      SUCCESS   \n",
       "264             2.00         2.00  custom-1-3840    None      SUCCESS   \n",
       "265             2.00         2.00  custom-1-3840    None      SUCCESS   \n",
       "258             2.00         2.00  custom-1-3840    None      SUCCESS   \n",
       "256            23.00        23.00  custom-1-3840    None      SUCCESS   \n",
       "\n",
       "     dstat_msg                                          dstat_log  \n",
       "309    Success  gs://gbsc-gcp-project-mvp-test-from-personalis...  \n",
       "246    Success  gs://gbsc-gcp-project-mvp-test-from-personalis...  \n",
       "231    Success  gs://gbsc-gcp-project-mvp-test-from-personalis...  \n",
       "218    Success  gs://gbsc-gcp-project-mvp-test-from-personalis...  \n",
       "2935   Success  gs://gbsc-gcp-project-mvp-test-from-personalis...  \n",
       "...        ...                                                ...  \n",
       "266    Success  gs://gbsc-gcp-project-mvp-test-from-personalis...  \n",
       "264    Success  gs://gbsc-gcp-project-mvp-test-from-personalis...  \n",
       "265    Success  gs://gbsc-gcp-project-mvp-test-from-personalis...  \n",
       "258    Success  gs://gbsc-gcp-project-mvp-test-from-personalis...  \n",
       "256    Success  gs://gbsc-gcp-project-mvp-test-from-personalis...  \n",
       "\n",
       "[7796 rows x 14 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "job_df=pd.concat([job_fq2u,job_gatk,job_gatk_stepm,job_fastqc,job_fastqc_t2t,job_flagstat,job_flagstat_t2t,job_vcfstats,job_vcfstats_t2t]).sort_values(['sample','job_group','job','fq2urg_gatkid'])\n",
    "display(job_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "## Cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vm_avg_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Custom CPU cost : 0.033174/CPU/Hour, # Custom Mem cost : 0.004446/GB/Hour, # Custom Disk cost : ???\n",
    "cpu_sd_cost = 0.033174\n",
    "memg_sd_cost = 0.004446\n",
    "\n",
    "cpu_pem_cost = 0.00698\n",
    "memg_pem_cost = 0.00094\n",
    "\n",
    "## Extract cpu and mem info.\n",
    "#temp=job_df.loc[:,['job','vm_type']]\n",
    "job_df.loc[:,'vm_std']=None\n",
    "job_df.loc[:,'vm_cpu']=0\n",
    "job_df.loc[:,'vm_mem']=0\n",
    "job_df[['vm_std','vm_cpu','vm_mem']]=[i.split('-') for i in job_df['vm_type']]\n",
    "job_df['vm_cpu']=[int(x) for x in job_df['vm_cpu']]\n",
    "job_df['vm_mem']=[int(x) for x in job_df['vm_mem']]\n",
    "#columnlist=['job','vm_type','vm_type','cpu','mem']\n",
    "#temp=temp[columnlist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FQ2U and GATK job unit cost with Standard VM\n",
    "job_df.loc[(job_df['job_group']=='GATK')&(job_df['job'].isin(['FQ2U','cromwell'])),'vm_avg_cost']= np.array(job_df.loc[(job_df['job_group']=='GATK')&(job_df['job'].isin(['FQ2U','cromwell'])),'vm_cpu'])*cpu_sd_cost/60 + np.array(job_df.loc[(job_df['job_group']=='GATK')&(job_df['job'].isin(['FQ2U','cromwell'])),'vm_mem'])*memg_sd_cost/60/1000\n",
    "\n",
    "# QC unit cost with Standard VM\n",
    "job_df.loc[(job_df['job_group']=='QC'),'vm_avg_cost']= np.array(job_df.loc[(job_df['job_group']=='QC'),'vm_cpu'])*cpu_sd_cost/60 + np.array(job_df.loc[(job_df['job_group']=='QC'),'vm_mem'])*memg_sd_cost/60/1000\n",
    "\n",
    "# GATK sub jobs' unit cost with Preemptible VM\n",
    "#job_df.loc[(job_df['job_group']=='GATK')&(job_df['job'].isin(['FQ2U','cromwell'])==False),'vm_avg_cost']= np.array(job_df.loc[(job_df['job_group']=='GATK')&(job_df['job'].isin(['FQ2U','cromwell'])==False),'vm_cpu'])*cpu_pem_cost/60 + np.array(job_df.loc[(job_df['job_group']=='GATK')&(job_df['job'].isin(['FQ2U','cromwell'])==False),'vm_mem'])*memg_pem_cost/60/1000 \n",
    "\n",
    "job_df.loc[(job_df['job_group']=='GATK')&(job_df['job'].isin(['FQ2U','cromwell'])==False),'vm_avg_cost']= \\\n",
    "    np.array(job_df.loc[(job_df['job_group']=='GATK')&(job_df['job'].isin(['FQ2U','cromwell'])==False),'vm_cpu'])*cpu_pem_cost/60 + \\\n",
    "    np.array(job_df.loc[(job_df['job_group']=='GATK')&(job_df['job'].isin(['FQ2U','cromwell'])==False),'vm_mem'])*memg_pem_cost/60/1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### job cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.8f' % x)\n",
    "\n",
    "## FQ2U\n",
    "job_df.loc[job_df['job']=='FQ2U','job_cost']=np.array(job_df.loc[job_df['job']=='FQ2U','job_runtime'])*np.array(job_df.loc[job_df['job']=='FQ2U','vm_avg_cost'])\n",
    "#merged_cost_df.head(2)\n",
    "\n",
    "## GATK\n",
    "job_df.loc[job_df['job']=='cromwell','job_cost']=np.array(job_df.loc[job_df['job']=='cromwell','job_runtime'])*np.array(job_df.loc[job_df['job']=='cromwell','vm_avg_cost'])\n",
    "#merged_cost_df[merged_cost_df['job']=='GATK'].head(2)\n",
    "\n",
    "## QC\n",
    "job_df.loc[job_df['job_group']=='QC','job_cost']=np.array(job_df.loc[job_df['job_group']=='QC','job_runtime'])*np.array(job_df.loc[job_df['job_group']=='QC','vm_avg_cost'])\n",
    "#merged_cost_df[merged_cost_df['job']=='GATK'].head(2)\n",
    "\n",
    "## GATK steps\n",
    "job_df.loc[(job_df['job_group']=='GATK')&(job_df['job']!='FQ2U') & (job_df['job']!='cromwell'),'job_cost']=np.array(job_df.loc[(job_df['job_group']=='GATK')&(job_df['job']!='FQ2U') & (job_df['job']!='cromwell'),'vm_cnt']) \\\n",
    "*np.array(job_df.loc[(job_df['job_group']=='GATK')&(job_df['job']!='FQ2U') & (job_df['job']!='cromwell'),'vm_avg_runtime'])*np.array(job_df.loc[(job_df['job_group']=='GATK')&(job_df['job']!='FQ2U') & (job_df['job']!='cromwell'),'vm_avg_cost'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnlist=['sample','job_group','job','fq2urg_gatkid','dup','vm_exp_cnt','vm_cnt','vm_avg_runtime','job_runtime','vm_type','vm_cpu','vm_mem','vm_disk','vm_avg_cost','job_cost','dstat_status','dstat_msg','dstat_log']\n",
    "job_df=job_df[columnlist]\n",
    "#job_df.to_csv('job-based-analysis-v058-1.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload CSV Files to BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:04,  4.18s/it]\n"
     ]
    }
   ],
   "source": [
    "table_id=account['BIGQUERY_DATASET']+'.job_based_analysis'\n",
    "projectid=account['GOOGLE_CLOUD_PROJECT']\n",
    "\n",
    "pandas_gbq.to_gbq(\n",
    "    job_df, table_id, project_id=projectid, if_exists='replace',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
