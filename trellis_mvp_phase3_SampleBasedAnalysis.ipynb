{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neo4J Trellis v1.2: Sample based Analysis\n",
    "\n",
    "    -  Check the success case only based on outputs\n",
    "    -  Load the account info from Google Cloud Storage\n",
    "    -  Remove Duplicate jobs and Duplicate jobs and nodes status\n",
    "    -  Add 'dup' column with the number of dupilcated jobs\n",
    "    \n",
    "================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the environment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install py2neo for querying Neo4J "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install py2neo\n",
    "\n",
    "# *** add python path of py2neo in system\n",
    "\n",
    "!pip3 install neotime\n",
    "!pip3 install neobolt\n",
    "!pip3 install pandas-gbq\n",
    "\n",
    "!pip3 install papermill\n",
    "\n",
    "!pip3 install google-cloud-storage\n",
    "!pip3 install matplotlib\n",
    "!pip3 install seaborn\n",
    "!pip3 install fsspec\n",
    "!pip3 install gcsfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import py2neo as neo\n",
    "from py2neo import Graph\n",
    "\n",
    "from google.cloud import storage\n",
    "import yaml\n",
    "\n",
    "import pandas as pd\n",
    "import pandas_gbq\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from google.cloud import bigquery\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Neo4J DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Load this from environment variables?\n",
    "bucket_info=''\n",
    "credential_info=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Option 1 : Read DB and Account Information in Google Storage (YAML)\n",
    "\n",
    "# create storage client\n",
    "storage_client = storage.Client()\n",
    "# get bucket with name\n",
    "bucket = storage_client.get_bucket(bucket_info)\n",
    "# get bucket data as blob\n",
    "blob = bucket.get_blob(credential_info)\n",
    "# convert to string\n",
    "yaml_data = blob.download_as_string()\n",
    "\n",
    "account = yaml.load(yaml_data, Loader=yaml.FullLoader)\n",
    "\n",
    "account['NEO4J_PASSPHRASE'] = \"tcfWvWpF9CkDxwtLv99Jjc6VVS3NvPyLrpFaERqfA6W3l9DrJvulhW88MUi6ueWAz0Y8MU0fpXxKZlmQgswN4A\"\n",
    "account['NEO4J_HOST'] = \"104.198.111.33\"\n",
    "\n",
    "## Main Account\n",
    "graph = Graph(account['NEO4J_SCHEME']+'://'+account['NEO4J_HOST']+\":\"+str(account['NEO4J_PORT']), auth=(account['NEO4J_USER'],account['NEO4J_PASSPHRASE']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Sample Status Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The number of nodes (Fastq, Ubam, Vcf, Cram, Crai) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count Fastqs per sample\n",
    "query = '''\n",
    "    MATCH (s:Sample)\n",
    "    WHERE NOT s.trellis_snvQa=true OR NOT EXISTS(s.trellis_snvQa)\n",
    "    WITH s\n",
    "    LIMIT 10000\n",
    "    MATCH (s)<-[:GENERATED]-(:Person)-[:HAS_BIOLOGICAL_OME|HAS_SEQUENCING_READS*2]->(f:Fastq)\n",
    "    RETURN s.sample AS sample, \n",
    "           COUNT(f) AS fastq\n",
    "'''\n",
    "start = time.time()\n",
    "num_fastq = graph.run(query).to_data_frame()\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "num_fastq.set_index('sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of Fastq read groups\n",
    "query = '''\n",
    "    MATCH (s:Sample)\n",
    "    WHERE NOT s.trellis_snvQa=true OR NOT EXISTS(s.trellis_snvQa)\n",
    "    WITH s\n",
    "    LIMIT 10000\n",
    "    MATCH (s)<-[:GENERATED]-(:Person)-[:HAS_BIOLOGICAL_OME|HAS_SEQUENCING_READS*2]->(f:Fastq)\n",
    "    RETURN s.sample AS sample,\n",
    "           f.readGroup AS rg,\n",
    "           COUNT(f.readGroup) AS rg_cnt\n",
    "'''\n",
    "start = time.time()\n",
    "num_fastq_rg = graph.run(query).to_data_frame()\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "num_fastq_rgm=num_fastq_rg.loc[num_fastq_rg['rg_cnt']==2,['sample','rg']]\n",
    "\n",
    "num_fastq_rgu=num_fastq_rgm['sample'].value_counts().rename_axis('sample').to_frame('fastq_rg')\n",
    "num_fastq_rgu.reset_index(inplace=True)\n",
    "num_fastq_rgu.set_index('sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of Ubam(s) per sample\n",
    "query = '''\n",
    "    MATCH (s:Sample)\n",
    "    WHERE NOT s.trellis_snvQa=true OR NOT EXISTS(s.trellis_snvQa)\n",
    "    WITH s\n",
    "    LIMIT 10000\n",
    "    MATCH (s)-[:GENERATED|WAS_USED_BY*4]->(u:Ubam)\n",
    "    RETURN s.sample AS sample,\n",
    "           COUNT(u) AS ubam,\n",
    "           COUNT(DISTINCT u.readGroup) AS ubam_rg\n",
    "'''\n",
    "#query = \"Match (s:Sample), (u:Ubam) WHERE s.sample = u.sample RETURN s.sample AS sample, count(u) AS ubam, count(distinct u.readGroup) as ubam_rg\"\n",
    "#query = \"Match (s:Sample)-[*]->(u:Ubam) RETURN DISTINCT s.sample AS sample, count(distinct u) AS ubam, count(distinct u.readGroup) as ubam_rg\"\n",
    "start = time.time()\n",
    "num_ubam = graph.run(query).to_data_frame()\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "num_ubam.set_index('sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of Vcfs per sample\n",
    "query = '''\n",
    "    MATCH (s:Sample)\n",
    "    WHERE NOT s.trellis_snvQa=true OR NOT EXISTS(s.trellis_snvQa)\n",
    "    WITH s\n",
    "    LIMIT 10000\n",
    "    MATCH (s)<-[:GENERATED]-(:Person)-[:HAS_BIOLOGICAL_OME]->(:Genome)-[:HAS_VARIANT_CALLS]->(v:Merged:Vcf)\n",
    "    RETURN s.sample AS sample, COUNT(v) AS vcf\n",
    "'''\n",
    "#query = \"Match (s:Sample), (v:Merged:Vcf) WHERE s.sample = v.sample RETURN s.sample AS sample, count(v) AS vcf\"\n",
    "#query = \"Match (s:Sample)-[*]->(v:Merged:Vcf) RETURN DISTINCT s.sample AS sample, count(distinct v) AS vcf\"\n",
    "start = time.time()\n",
    "num_vcf = graph.run(query).to_data_frame()\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "num_vcf.set_index('sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of Crams per sample\n",
    "query = '''\n",
    "    MATCH (s:Sample)\n",
    "    WHERE NOT s.trellis_snvQa=true OR NOT EXISTS(s.trellis_snvQa)\n",
    "    WITH s\n",
    "    LIMIT 10000\n",
    "    MATCH (s)<-[:GENERATED]-(:Person)-[:HAS_BIOLOGICAL_OME]->(:Genome)-[:HAS_SEQUENCING_READS]->(cm:Cram)\n",
    "    RETURN s.sample AS sample, \n",
    "           COUNT(cm) AS cram\n",
    "'''\n",
    "#query = \"Match (s:Sample), (cm:Cram) WHERE s.sample = cm.sample RETURN s.sample AS sample, count(cm) AS cram\"\n",
    "#query = \"Match (s:Sample)-[*]->(cm:Cram) RETURN DISTINCT s.sample AS sample, count(distinct cm) AS cram\"\n",
    "start = time.time()\n",
    "num_cram = graph.run(query).to_data_frame()\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "num_cram.set_index('sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of Crais per sample\n",
    "query = '''\n",
    "    MATCH (s:Sample)\n",
    "    WHERE NOT s.trellis_snvQa=true OR NOT EXISTS(s.trellis_snvQa)\n",
    "    WITH s\n",
    "    LIMIT 10000\n",
    "    MATCH (s)<-[:GENERATED]-(:Person)-[:HAS_BIOLOGICAL_OME]->(:Genome)-[:HAS_SEQUENCING_READS]->(:Cram)-[:HAS_INDEX]->(ci:Crai)\n",
    "    RETURN s.sample AS sample,\n",
    "           COUNT(ci) AS crai\n",
    "'''\n",
    "#query = \"Match (s:Sample), (ci:Crai) WHERE s.sample = ci.sample RETURN s.sample AS sample, count(ci) AS crai\"\n",
    "#query = \"Match (s:Sample)-[*]->(ci:Crai) RETURN DISTINCT s.sample AS sample, count(distinct ci) AS crai\"\n",
    "start = time.time()\n",
    "num_crai = graph.run(query).to_data_frame()\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "num_crai.set_index('sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The number of jobs (FQ2U, GATK) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fq2u\n",
    "query = '''\n",
    "    MATCH (s:Sample)\n",
    "    WHERE NOT s.trellis_snvQa=true OR NOT EXISTS(s.trellis_snvQa)\n",
    "    WITH s\n",
    "    LIMIT 10000\n",
    "    MATCH (s)-[:GENERATED|WAS_USED_BY*3]->(e:Job:FastqToUbam)\n",
    "    RETURN s.sample AS sample,\n",
    "           COUNT(DISTINCT e) AS job_fq2u\n",
    "'''\n",
    "#query = \"Match (s:Sample), (e:Job:Dsub {name:'fastq-to-ubam'}) WHERE s.sample = e.sample RETURN s.sample AS sample, count(e) AS job_fq2u\"\n",
    "#query = \"Match (s:Sample)-[*]->(e:Job:Dsub {name:'fastq-to-ubam'}) RETURN s.sample AS sample, count(distinct e) AS job_fq2u\"\n",
    "start = time.time()\n",
    "num_fq2u = graph.run(query).to_data_frame()\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "num_fq2u.set_index('sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gatk\n",
    "query = '''\n",
    "    MATCH (s:Sample)\n",
    "    WHERE NOT s.trellis_snvQa=true OR NOT EXISTS(s.trellis_snvQa)\n",
    "    WITH s\n",
    "    LIMIT 10000\n",
    "    MATCH (s)-[:GENERATED|WAS_USED_BY*5]->(g:Job:CromwellWorkflow:Gatk5Dollar)\n",
    "    RETURN s.sample AS sample,\n",
    "           COUNT(DISTINCT g) AS job_gatk\n",
    "'''\n",
    "#query = \"Match (s:Sample), (g:Job:CromwellWorkflow) WHERE s.sample = g.sample RETURN s.sample AS sample, count(g) AS job_gatk\"\n",
    "#query = \"Match (s:Sample)-[*]->(g:Job:CromwellWorkflow) RETURN s.sample AS sample, count(distinct g) AS job_gatk\"\n",
    "start = time.time()\n",
    "num_gatk = graph.run(query).to_data_frame()\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "num_gatk.set_index('sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Job running check (FQ2U, GATK) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get count of completed FQ2U jobs per sample\n",
    "query_2 = '''\n",
    "    MATCH (s:Sample)\n",
    "    WHERE NOT s.trellis_snvQa=true OR NOT EXISTS(s.trellis_snvQa)\n",
    "    WITH s\n",
    "    LIMIT 10000\n",
    "    MATCH (s)-[:GENERATED|WAS_USED_BY*3]->(e:Job:FastqToUbam)\n",
    "    WITH s, COLLECT(DISTINCT(e)) AS jobs\n",
    "    UNWIND jobs AS job\n",
    "    RETURN s.sample AS sample,\n",
    "           job.status AS status,\n",
    "           COUNT(job) AS count\n",
    "'''\n",
    "\n",
    "query = '''\n",
    "    MATCH (s:Sample)\n",
    "    WHERE NOT s.trellis_snvQa=true OR NOT EXISTS(s.trellis_snvQa)\n",
    "    WITH s\n",
    "    LIMIT 10000\n",
    "    MATCH (s)-[:GENERATED|WAS_USED_BY*3]->(e:Job:FastqToUbam)\n",
    "    WHERE e.status = \"STOPPED\"\n",
    "    AND e.name = \"fastq-to-ubam\"\n",
    "    RETURN s.sample AS sample,\n",
    "           COUNT(DISTINCT e) AS run_fq2u\n",
    "'''\n",
    "\n",
    "#query = \"Match (s:Sample), (e:Job:FastqToUbam) WHERE s.sample = e.sample and e.status = 'STOPPED' RETURN s.sample AS sample, count(e) AS run_fq2u\"\n",
    "start = time.time()\n",
    "run_fq2u = graph.run(query).to_data_frame()\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "run_fq2u.set_index('sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get count of completed GATK jobs per sample\n",
    "query = '''\n",
    "    MATCH (s:Sample)\n",
    "    WHERE NOT s.trellis_snvQa=true OR NOT EXISTS(s.trellis_snvQa)\n",
    "    WITH s\n",
    "    LIMIT 10000\n",
    "    MATCH (s)-[:GENERATED|WAS_USED_BY*5]->(g:Job:CromwellWorkflow:Gatk5Dollar)\n",
    "    WHERE g.status = \"STOPPED\"\n",
    "    AND g.name = \"gatk-5-dollar\"\n",
    "    RETURN s.sample AS sample,\n",
    "           count(DISTINCT g) AS run_gatk\n",
    "'''\n",
    "#query = \"Match (s:Sample), (g:Job:CromwellWorkflow) WHERE s.sample = g.sample and g.status = 'STOPPED' RETURN s.sample AS sample, count(g) AS run_gatk\"\n",
    "start = time.time()\n",
    "run_gatk = graph.run(query).to_data_frame()\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "run_gatk.set_index('sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add 'on_process' column\n",
    "running_df=num_fq2u.merge(run_fq2u, how='outer').merge(num_gatk, how='outer').merge(run_gatk, how='outer')\n",
    "running_df.fillna(0,inplace=True)\n",
    "\n",
    "running_df['run_fq2u']=running_df['job_fq2u']-running_df['run_fq2u']\n",
    "running_df['run_gatk']=running_df['job_gatk']-running_df['run_gatk']\n",
    "running_df['run_fq2u']=['done' if (i==0) else 'running' for i in (running_df['run_fq2u'])]\n",
    "running_df['run_gatk']=['done' if (i==0) else 'running' for i in (running_df['run_gatk'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_df=running_df[['sample','run_fq2u','run_gatk']]\n",
    "running_df.set_index('sample')\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge all node and job dfs to one df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- only nodes\n",
    "#pre_sample_qc_df=num_fastq.merge(num_ubam, how='outer').merge(num_vcf, how='outer').merge(num_cram, how='outer').merge(num_crai, how='outer')\n",
    "#columnlist=[\"sample\",\"fastq\",\"ubam\",\"vcf\",\"cram\",\"crai\"]\n",
    "\n",
    "#-- nodes and jobs\n",
    "pre_sample_qc_df=num_fastq.merge(num_fastq_rgu, how='outer').merge(num_ubam, how='outer').merge(num_vcf, how='outer').merge(num_cram, how='outer').merge(num_crai, how='outer').merge(num_fq2u,how='outer').merge(num_gatk,how='outer').merge(running_df,how='outer')\n",
    "columnlist=[\"sample\",\"run_fq2u\",\"run_gatk\",\"fastq\",\"fastq_rg\",\"ubam\",\"ubam_rg\",\"vcf\",\"cram\",\"crai\",\"job_fq2u\",\"job_gatk\"]\n",
    "numsample=len(pre_sample_qc_df)\n",
    "print(\"The number of samples : \" + str(numsample) + \"\\n\")\n",
    "\n",
    "pre_sample_qc_df=pre_sample_qc_df[columnlist]\n",
    "pre_sample_qc_df.fillna(0,inplace=True)\n",
    "#pre_sample_qc_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select only completed cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_qc_df=pre_sample_qc_df.loc[(pre_sample_qc_df['run_fq2u']=='done')&(pre_sample_qc_df['run_gatk']=='done'),[\"sample\",\"fastq\",\"fastq_rg\",\"ubam\",\"ubam_rg\",\"vcf\",\"cram\",\"crai\",\"job_fq2u\",\"job_gatk\"]]\n",
    "numsample=len(sample_qc_df)\n",
    "print(\"The number of samples : \" + str(numsample) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification based on sample status and success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##-- Passed\n",
    "\n",
    "sample_qc_df.loc[((sample_qc_df['ubam']>=sample_qc_df['fastq']/2)&(sample_qc_df['ubam_rg']==sample_qc_df['fastq_rg'])&(sample_qc_df['vcf']>=1)&(sample_qc_df['cram']>=1) \\\n",
    "                 &(sample_qc_df['crai']>=1)),'status']=\"success\"\n",
    "\n",
    "#-Pass\n",
    "sample_qc_df.loc[(sample_qc_df['status'].isin([\"success\"])), 'pass'] = \"pass\"\n",
    "\n",
    "##-- failed\n",
    "\n",
    "#- 4. no fq2u jobs\n",
    "sample_qc_df.loc[((sample_qc_df['ubam']<sample_qc_df['fastq']/2)&(sample_qc_df['vcf']==0)&(sample_qc_df['cram']==0) \\\n",
    "                                   &(sample_qc_df['crai']==0))&((sample_qc_df['job_fq2u']<sample_qc_df['fastq']/2)&(sample_qc_df['job_gatk']==0)),'status']=\"no fq2u\"\n",
    "#- 5. failed fq2u jobs\n",
    "sample_qc_df.loc[((sample_qc_df['ubam']<sample_qc_df['fastq']/2)&(sample_qc_df['vcf']==0)&(sample_qc_df['cram']==0) \\\n",
    "                                   &(sample_qc_df['crai']==0))&((sample_qc_df['job_fq2u']>=sample_qc_df['fastq']/2)&(sample_qc_df['job_gatk']==0)),'status']=\"failed fq2u\"\n",
    "#- 6. failed gatk jobs\n",
    "sample_qc_df.loc[(sample_qc_df['ubam']>=sample_qc_df['fastq']/2)&((sample_qc_df['vcf']<1)|(sample_qc_df['cram']<1) \\\n",
    "                                   |(sample_qc_df['crai']<1))&((sample_qc_df['job_fq2u']>=sample_qc_df['fastq']/2)&(sample_qc_df['job_gatk']>=1)),'status']=\"failed gatk\"\n",
    "#- 7. no gatk jobs\n",
    "sample_qc_df.loc[((sample_qc_df['ubam']>=sample_qc_df['fastq']/2)&(sample_qc_df['vcf']==0)&(sample_qc_df['cram']==0) \\\n",
    "                                   &(sample_qc_df['crai']==0)&(sample_qc_df['job_gatk']==0)),'status']=\"no gatk\"\n",
    "#- 8. missing rg jobs\n",
    "sample_qc_df.loc[(sample_qc_df['ubam']>=sample_qc_df['fastq']/2)&(sample_qc_df['job_fq2u']>=sample_qc_df['fastq']/2)&(sample_qc_df['fastq_rg']!=sample_qc_df['ubam_rg']),'status']=\"missing rg\"\n",
    "\n",
    "\n",
    "#- Fail\n",
    "sample_qc_df.loc[(sample_qc_df['status'].isin([\"no fq2u\", \"failed fq2u\", \"failed gatk\", \"no gatk\",\"missing rg\"])), 'pass'] = \"fail\"\n",
    "\n",
    "##-- Check unclassified samples.\n",
    "num_unclassified = len(sample_qc_df[sample_qc_df.status.isna()==True])\n",
    "print(\"The number of unclassified samples : \" + str(num_unclassified)+\"\\n\")\n",
    "\n",
    "if num_unclassified != 0 :\n",
    "    display(sample_qc_df[sample_qc_df.status.isna()==True])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplication Job Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_qc_df['dup']=(sample_qc_df['job_fq2u']-sample_qc_df['ubam_rg'])+(sample_qc_df['job_gatk']-1)\n",
    "sample_qc_df['dup']= [0 if i < 0 else i for i in sample_qc_df['dup']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##-- Display of this table\n",
    "pd.set_option('display.float_format', lambda x: '%.f' % x)\n",
    "\n",
    "display(sample_qc_df[sample_qc_df['status']=='success'].head(2))\n",
    "#display(sample_qc_df[sample_qc_df['status']=='duplicated jobs'].head(13))\n",
    "#display(sample_qc_df[sample_qc_df['status']=='duplicated nodes'].head(7))\n",
    "display(sample_qc_df[sample_qc_df['status']=='no fq2u'].head(2))\n",
    "display(sample_qc_df[sample_qc_df['status']=='failed fq2u'].head(2))\n",
    "display(sample_qc_df[sample_qc_df['status']=='no gatk'].head(4))\n",
    "display(sample_qc_df[sample_qc_df['status']=='failed gatk'].head(5))\n",
    "display(sample_qc_df[sample_qc_df['status']=='missing rg'].head(9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Status Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The number of samples by status and success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_status_qc=sample_qc_df['status'].value_counts().to_frame()\n",
    "stat_status_qc['rate']=100*(stat_status_qc['status']/numsample)\n",
    "temp = sample_qc_df[['status','dup']]\n",
    "temp['dup']=[1 if i > 0 else 0 for i in temp['dup']]\n",
    "stat_status_qc['dup']=temp.groupby('status').sum()\n",
    "stat_status_qc['dup_rate']=100*(stat_status_qc['dup']/stat_status_qc['status'])\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "#stat_status_qc=stat_status_qc.reindex(index = ['success', 'duplicated jobs', 'duplicated nodes', 'no fq2u', 'failed fq2u', 'no gatk', 'failed gatk','missing rg'])\n",
    "stat_status_qc=stat_status_qc.reindex(index = ['success', 'no fq2u', 'failed fq2u', 'no gatk', 'failed gatk','missing rg'])\n",
    "stat_status_qc=stat_status_qc.replace(np.nan,0)\n",
    "display(stat_status_qc)\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "print(\"Success Samples : \" + str(sum(stat_status_qc['status'][0:3])))\n",
    "print(\"Failed Samples : \" + str(sum(stat_status_qc['status'][3:7])))\n",
    "print(\"Success Rate : \" + str(sum(stat_status_qc['rate'][0:3])) + \"%\")\n",
    "print(\"Failed Rate : \" + str(sum(stat_status_qc['rate'][3:7])) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import style\n",
    "import matplotlib as mpl\n",
    "style.use('ggplot')\n",
    "\n",
    "fig = plt.figure(1, figsize=(10,10))\n",
    "labels = ['Pass','Fail']\n",
    "colors = ['green','red']\n",
    "ratio = [sum(stat_status_qc['rate'][0:3]),sum(stat_status_qc['rate'][3:7])]\n",
    "patches, texts, autotexts=plt.pie(ratio, labels=labels, colors=colors, autopct='%.2f%%', shadow=False, startangle=30, textprops={'fontsize': 20})\n",
    "texts[0].set_fontsize(20)\n",
    "texts[1].set_fontsize(20)\n",
    "plt.show()\n",
    "#plt.savefig('./success_rate.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload CSV Files to BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnlist=[\"sample\",\"pass\",\"status\",\"dup\",\"fastq\",\"fastq_rg\",\"ubam\",\"ubam_rg\",\"vcf\",\"cram\",\"crai\",\"job_fq2u\",\"job_gatk\"]\n",
    "sample_qc_df_simple=sample_qc_df[columnlist]\n",
    "sample_qc_df_simple.loc[sample_qc_df_simple['pass']=='fail',:].to_csv('gs://'+account['TRELLIS_BUCKET']+'/analysis-notebooks/gatk-failed-samples.csv')\n",
    "\n",
    "# Create CSV with sample, [pass/fail] to update :Sample in Neo4j\n",
    "sample_qc_status = sample_qc_df[([\"sample\",\"pass\"])]\n",
    "sample_qc_status.to_csv('gs://'+account['TRELLIS_BUCKET']+'/analysis-notebooks/sample-status.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_id = account['BIGQUERY_DATASET'] + '.sample_based_analysis'\n",
    "projectid = account['GOOGLE_CLOUD_PROJECT']\n",
    "\n",
    "pandas_gbq.to_gbq(\n",
    "    sample_qc_df_simple, table_id, project_id=projectid, if_exists='append',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
